{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN Model\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "# !pip uninstall torch_xla\n",
    "# !pip3 install https://storage.googleapis.com/tpu-pytorch/wheels/tpuvm/torch_xla-1.10-cp38-cp38-linux_x86_64.whl\n",
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "import time\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "#References from documentation\n",
    "start = time.time()\n",
    "trans = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandAugment(),\n",
    "    torchvision.transforms.AutoAugment(),\n",
    "#     torchvision.transforms.RandomHorizontalFlip(p=0.5)\n",
    "#     torchvision.transforms.RandomEqualize(p=0.5),\n",
    "    torchvision.transforms.RandomVerticalFlip(p=0.5),\n",
    "#     torchvision.transforms.RandomInvert(p=0.5),\n",
    "    torchvision.transforms.Resize(size =(300,300)),\n",
    "    ToTensor()\n",
    "])\n",
    "batchS = 100\n",
    "data = torchvision.datasets.ImageFolder('/kaggle/input/wild-animals/Wild_animals_512',transform = trans)\n",
    "train_data,test_data = torch.utils.data.random_split(data,[round(data.__len__()*0.6),round(data.__len__()*0.4)])\n",
    "​\n",
    "#valid_data,testy_data = torch.utils.data.random_split(test_data,[round(test_data.__len__()*0.5),round(test_data.__len__()*0.5)])\n",
    "valid_data,testy_data = torch.utils.data.random_split(test_data,[345,344])\n",
    "train_load = DataLoader(train_data,shuffle = True,batch_size= batchS,drop_last=True)\n",
    "valid_load = DataLoader(valid_data,shuffle = True,batch_size= batchS,drop_last = True)\n",
    "test_load = DataLoader(testy_data,shuffle = True,batch_size= batchS,drop_last = True)\n",
    "print(len(data))\n",
    "​\n",
    "print('done')\n",
    "print(data.class_to_idx)\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Network referenced from  https://pytorch.org/tutorials/beginner/examples_nn/polynomial_module.html\n",
    "%matplotlib inline\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#Initial Model code referenced from https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n",
    "#Code from the 'Define the Network' section\n",
    "#Experiment 1\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #Feature extraction\n",
    "        self.conv= nn.Conv2d(3,64,9)\n",
    "        self.conv2 = nn.Conv2d(64,128,5)\n",
    "        self.conv3 = nn.Conv2d(128,256,5)\n",
    "        self.conv4 = nn.Conv2d(256,512,5)\n",
    "        self.conv5 = nn.Conv2d(512,1024,5)\n",
    "        self.bat2d1 = nn.BatchNorm2d(64)\n",
    "        self.bat2d2 = nn.BatchNorm2d(128)\n",
    "        self.bat2d3 = nn.BatchNorm2d(256)\n",
    "        self.bat2d4 = nn.BatchNorm2d(512)\n",
    "        self.bat2d5 = nn.BatchNorm2d(1024)\n",
    "        self.bat1d = nn.BatchNorm1d(196)\n",
    "        self.bat1d2 = nn.BatchNorm1d(256)\n",
    "#         self.bat1d3 = nn.BatchNorm1d(512)\n",
    "        self.dropout = nn.Dropout(p= 0.8)\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "\n",
    "        \n",
    "        #Classification layer\n",
    "        self.lin = nn.Linear(1024*5*5,196)\n",
    "        self.lin3 = nn.Linear(196,256)\n",
    "#         self.lin4 = nn.Linear(256,512)\n",
    "        self.lin2 = nn.Linear(256,6)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #First two lines are referenced\n",
    "        x = F.max_pool2d(F.relu(self.conv(x)),(2,2))\n",
    "        x=self.bat2d1(x)\n",
    "        self.dropout(x)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),(2,2))\n",
    "        x=self.bat2d2(x)\n",
    "        self.dropout(x)\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)),(2,2))\n",
    "        x=self.bat2d3(x)\n",
    "        self.dropout(x)\n",
    "        x = F.max_pool2d(F.relu(self.conv4(x)),(2,2))\n",
    "        x=self.bat2d4(x)\n",
    "        self.dropout(x)\n",
    "        x = F.max_pool2d(F.relu(self.conv5(x)),(2,2))\n",
    "        x=self.bat2d5(x)\n",
    "        self.dropout(x)\n",
    "        print(x.shape)\n",
    "        #Flattening tensors\n",
    "        x = torch.flatten(x,1)\n",
    "#         print(x.shape)\n",
    "        x = F.relu(self.lin(x))\n",
    "        self.bat1d(x)\n",
    "        x= F.relu(self.lin3(x))\n",
    "        self.bat1d2(x)\n",
    "        self.dropout2(x)\n",
    "#         x= F.relu(self.lin4(x))\n",
    "#         self.bat1d3(x)\n",
    "#         self.dropout2(x)\n",
    "        x = F.softmax(self.lin2(x),dim = 1)\n",
    "        return x\n",
    "    \n",
    "model = Model()\n",
    "device = torch.device(\"cuda:0\")\n",
    "# model.to(torch.device(\"cuda:0\"))\n",
    "#[7] Referenced from pytorch tutorial: https://pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html#create-model-and-dataparallel\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "# model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01,weight_decay=0.0000000001)\n",
    "lossfn = nn.CrossEntropyLoss()\n",
    "lossx = 0\n",
    "lossxt = 0\n",
    "l1 = 0\n",
    "\n",
    "#count = []\n",
    "lossgraph = []\n",
    "testgraph = []\n",
    "#Code referenced from https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "#I extracted data from the DataLoaders following the tutorial above\n",
    "#I used two for loops and called the optimizer and loss functions in a similar way\n",
    "#From the 'Define the network' section of the webpage.\n",
    "for epoch in range(550):\n",
    "    print(epoch)\n",
    "    \n",
    "    for i,data in enumerate(train_load, 0):\n",
    "        lossx = 0\n",
    "        pics, label = data\n",
    "#         pics, label = pics.cuda(), label.cuda()\n",
    "#         pics,label = pics.to(device),label.to(device)\n",
    "        \n",
    "        #print(pics.shape)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(pics)\n",
    "        #reshaping label\n",
    "        #label = torch.tensor(label)\n",
    "        labely = torch.zeros(batchS,6)\n",
    "        for j in range(batchS):\n",
    "            labely[j][label[j]] = 1\n",
    "        #print(output)\n",
    "#         labely = labely.cuda()\n",
    "#         labely = labely.to(device)\n",
    "#         https://stackoverflow.com/questions/58172188/how-to-add-l1-regularization-to-pytorch-nn-model\n",
    "       \n",
    "#         for param in model.parameters():\n",
    "#             l1 += param.abs().sum()\n",
    "        loss = lossfn(output,labely) \n",
    "        #lossgraph.append(loss)\n",
    "        loss.backward()\n",
    "        lossx += loss\n",
    "        #print(output)\n",
    "        optimizer.step()\n",
    "        #graphing loss\n",
    "        \n",
    "        #print(len(lossgraph),epoch,i)\n",
    "    lossgraph.append(lossx.item())\n",
    "\n",
    "    testingloss = nn.CrossEntropyLoss()\n",
    "#     classes = {0:'Motorbikes',1:'Airplanes',2:'Schooner'}\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i, data in enumerate(valid_load,0):\n",
    "        lossxt = 0\n",
    "        pics,label = data\n",
    "#         pics, label = pics.cuda(), label.cuda()\n",
    "#         pics,label = pics.to(device),label.to(device)\n",
    "        #print(pics.shape)\n",
    "        output = model(pics)\n",
    "        labely = torch.zeros(batchS,6)\n",
    "        for j in range(batchS):\n",
    "            labely[j][label[j]] = 1\n",
    "            #print(output)\n",
    "#         labely = labely.cuda()\n",
    "#         labely = labely.to(device)\n",
    "        loss = testingloss(output,labely)\n",
    "        lossxt += loss.item()\n",
    "        #print(output)\n",
    "        maxele,maxindx = torch.max(output,1)\n",
    "        for j in range(batchS):\n",
    "#             print('Prediction: {0}, Answer: {1}'.format(classes[maxindx[j].item()],classes[label[j].item()]))\n",
    "            #print(maxindx[j].item(),label[j].item())\n",
    "            if(torch.eq(maxindx[j],label[j])):\n",
    "                correct = correct +1\n",
    "            total = total+1\n",
    "    #print(correct,total)\n",
    "    \n",
    "    #plt.legend('Training set','Validation set')\n",
    "    accuracy = (correct/total)*100\n",
    "    #print('Accuracy is {0:.2f}%'.format(accuracy))\n",
    "    testgraph.append(lossxt)\n",
    "\n",
    "        #plt.ylim(4e-1,7e-1)\n",
    "#plt.yscale('log')\n",
    "#plt.figure(figsize = (1,1))\n",
    "#print(testgraph)\n",
    "\n",
    "#plt.yscale('log')\n",
    "PATH = '/kaggle/working/state_dict_model.pt'\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.yscale('log')\n",
    "plt.plot(testgraph,'r-')\n",
    "plt.plot(lossgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation cell\n",
    "#Code referenced from https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "#I extracted data from the DataLoaders following the tutorial above\n",
    "#I used two for loops and called the optimizer and loss functions in a similar way\n",
    "#From the 'Define the network' section of the webpage.\n",
    "'''\n",
    "\n",
    "'''\n",
    "#testgraph = []\n",
    "#testingloss = nn.CrossEntropyLoss()\n",
    "total = 0\n",
    "correct = 0\n",
    "cl = []\n",
    "pl = []\n",
    "for i, data in enumerate(valid_load,0):\n",
    "    lossxt = 0\n",
    "    pics,label = data\n",
    "    pics, label = pics.cuda(), label.cuda()\n",
    "#     pics,label = pics.to(device),label.to(device)\n",
    "    #print(pics.shape)\n",
    "    output = model(pics)\n",
    "    labely = torch.zeros(batchS,6)\n",
    "    for j in range(batchS):\n",
    "        labely[j][label[j]] = 1\n",
    "        #print(output)\n",
    "    labely = labely.cuda()\n",
    "    #loss = testingloss(output,labely)\n",
    "    #lossxt += loss.item()\n",
    "    #print(output)\n",
    "    maxele,maxindx = torch.max(output,1)\n",
    "    #testgraph.append(lossxt)\n",
    "    for j in range(batchS):\n",
    "#         print('Prediction: {0}, Answer: {1}'.format(classes[maxindx[j].item()],classes[label[j].item()]))\n",
    "        print(maxindx[j].item(),label[j].item())\n",
    "        cl.append(label[j].item())\n",
    "        pl.append(maxindx[j].item())\n",
    "        if(torch.eq(maxindx[j],label[j])):\n",
    "            correct = correct +1\n",
    "            print('Yay')\n",
    "        total = total+1\n",
    "print(correct,total)\n",
    "#plt.plot(testgraph)\n",
    "#plt.legend('Training set','Validation set')\n",
    "accuracy = (correct/total)*100\n",
    "fscore = f1_score(cl,pl,average='macro')\n",
    "print(\"F1 score is {0:.2f}\".format(fscore))\n",
    "print('Accuracy is {0:.2f}%'.format(accuracy))\n",
    "stop = time.time()\n",
    "print(f'time is {stop-start}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing data\n",
    "#Code referenced from https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "#I extracted data from the DataLoaders following the tutorial above\n",
    "#I used two for loops and called the optimizer and loss functions in a similar way.\n",
    "#From the 'Define the network' section of the webpage.\n",
    "total = 0\n",
    "correct =0\n",
    "cl2 = []\n",
    "pl2 = []\n",
    "for i2, data2 in enumerate(test_load,0):\n",
    "    #lossxt = 0\n",
    "    pics,label = data2\n",
    "    pics, label = pics.cuda(), label.cuda()\n",
    "#     pics,label = pics.to(device),label.to(device)\n",
    "    #print(pics.shape)\n",
    "    output = model(pics)\n",
    "    labely = torch.zeros(batchS,6)\n",
    "    for j in range(batchS):\n",
    "        labely[j][label[j]] = 1\n",
    "        #print(output)\n",
    "#     labely = labely.cuda()\n",
    "#     loss = testingloss(output,labely)\n",
    "    #lossxt += loss\n",
    "    #print(output)\n",
    "    maxele,maxindx = torch.max(output,1)\n",
    "    #testgraph.append(lossxt)\n",
    "    for j in range(batchS):\n",
    "        #print('Prediction: {0}, Answer: {1}'.format(classes[maxindx[j].item()],classes[label[j].item()]))\n",
    "        #print(maxindx[j].item(),label[j].item())\n",
    "        cl2.append(label[j].item())\n",
    "        pl2.append(maxindx[j].item())\n",
    "        if(torch.eq(maxindx[j],label[j])):\n",
    "            correct = correct +1\n",
    "        total = total+1\n",
    "print(correct,total)\n",
    "#plt.plot(testgraph)\n",
    "accuracy = (correct/total)*100\n",
    "fscore = f1_score(cl2,pl2,average='macro')\n",
    "print(\"F1 score is {0:.2f}\".format(fscore))\n",
    "print('Accuracy is {0:.2f}%'.format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
